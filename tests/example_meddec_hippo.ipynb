{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jrhy6LVovYOl"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import os\n",
        "import sys\n",
        " \n",
        "!git clone https://$BITBUCKET_AUTH@bitbucket.org/reisert/patchwork.git\n",
        "!mkdir models\n",
        "\n",
        "import sys \n",
        "import os\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as npss\n",
        "import tensorflow as tf\n",
        "import math\n",
        "import json\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import patchwork as patchwork\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download data "
      ],
      "metadata": {
        "id": "Ngx7HiV2mkU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data from medical decathlon repo\n",
        "taskname = 'Task04_Hippocampus'\n",
        "!gdown --id 1RzPB1_bqzQhlWvU-YGvZzhx2omcDh38C\n",
        "!tar -xf Task04_Hippocampus.tar\n",
        "\n",
        "# prepare json for patchwork\n",
        "dataset = json.load(open(taskname + '/dataset.json'))\n",
        "contrasts = {}\n",
        "labels = {}\n",
        "items = []\n",
        "label_indices = list(map(int,dataset['labels'].keys()))[1:]\n",
        "cnt = 1\n",
        "for obj in dataset['training']:\n",
        "     id = 'item%i' % cnt\n",
        "     contrasts[id] = taskname + obj['image'][1:]\n",
        "     labels[id] =  taskname + obj['label'][1:]\n",
        "     items.append(id)\n",
        "     cnt = cnt + 1\n"
      ],
      "metadata": {
        "id": "KF22XqpfQ8gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the model"
      ],
      "metadata": {
        "id": "C4OBW45omrWf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QETi6fTzZXgE"
      },
      "outputs": [],
      "source": [
        "\n",
        "modelfi = \"models/\" + taskname  # here our model is saved\n",
        "#reinit_model = True\n",
        "\n",
        "# dim of problem (2D/3D)\n",
        "nD = 3\n",
        "\n",
        "### PATCHING OPTIONS\n",
        "patching = {        \n",
        "    \"depth\":3,                    \n",
        "    \"scheme\":{ \n",
        "        \"patch_size\":[32,32,32],                \n",
        "        \"destvox_mm\": None,\n",
        "        \"destvox_rel\":[1,1,1],\n",
        "        \"fov_mm\":None,\n",
        "        \"fov_rel\":[0.8,0.8,0.8],\n",
        "     },\n",
        "    \"categorial_label\" :label_indices,\n",
        "    \"normalize_input\" : 'patch_m0s1',\n",
        "    }\n",
        "\n",
        "### NETWORK OPTIONS\n",
        "network = {    \n",
        "    \"blockCreator\": lambda level,outK,input_shape : \n",
        "        patchwork.customLayers.createUnet_v2(depth=3,outK=outK,nD=nD,\n",
        "                                             input_shape=input_shape,\n",
        "                                             feature_dim=[4,8,8,8,16],\n",
        "                                             nonlin='relu',\n",
        "                                             ),\n",
        "    \"finalBlock\": tf.keras.layers.Activation('sigmoid'),\n",
        "    \"intermediate_loss\":True,          \n",
        "    \"forward_type\":\"bridge\",\n",
        "    }\n",
        "\n",
        "## DATA IMPORT OPTIONS\n",
        "loading = {\n",
        "    \"crop_fdim\":None,\n",
        "    \"crop_fdim_labels\":None,\n",
        "    \"integer_labels\":True,      # needed for categorial/index label images\n",
        "    \"threshold\":None,\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "def get_data(n=None):\n",
        "   return patchwork.improc_utils.load_data_structured(\n",
        "                       contrasts=[contrasts],labels=[labels],subjects=items,max_num_data=n, **loading)\n",
        "\n",
        "print(\"\\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>> loading first example for init.\")\n",
        "\n",
        "with tf.device(\"/cpu:0\"):    \n",
        "    tset,lset,rset,subjs = get_data(1)\n",
        "    \n",
        "if len(tset) == 0:\n",
        "    print(\"Error: No data found!\")\n",
        "    raise NameError('No data found! Stopping ...  ')\n",
        "\n",
        "# load or generate model\n",
        "if os.path.isfile(modelfi+\".json\") and not reinit_model:\n",
        "    print(\"\\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> model already existing, loading \")\n",
        "    themodel = patchwork.PatchWorkModel.load(modelfi,immediate_init=True,notmpfile=True)\n",
        "else:\n",
        "\n",
        "    print(\"\\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> creating new model\")    \n",
        "    \n",
        "    patching['ndim'] = nD    \n",
        "    network['modelname'] = modelfi  \n",
        "\n",
        "    if 'finalBlock' not in network:\n",
        "        network['finalBlock']=layers.Activation('sigmoid')\n",
        "    if patching['categorial_label'] is not None:\n",
        "        network['num_labels']= len(patching['categorial_label'])\n",
        "    else:\n",
        "        network['num_labels']= lset[0].shape[nD+1]\n",
        "    print('numlabels:' + str(network['num_labels']))\n",
        "    \n",
        "    # create model\n",
        "    cgen = patchwork.CropGenerator(**patching)\n",
        "    themodel = patchwork.PatchWorkModel(cgen, **network)\n",
        "    \n",
        "    print(\"\\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>> initializing network\")\n",
        "    dataexample = tset[0][0:1,...]    \n",
        "    tmp = themodel.apply_full(dataexample,resolution=rset[0],repetitions=100,generate_type='random',verbose=True)\n",
        "    \n",
        "    \n",
        "\n",
        "print(\"\\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>> model summary\")\n",
        "themodel.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training of the model"
      ],
      "metadata": {
        "id": "DLvWVT30m3bk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDH5cXNqZrv6"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "## TRAINING OPTION\n",
        "training = {\n",
        "   \"num_patches\":25,\n",
        "   \"augment\": {\"dphi\":0.2, \"flip\":[0,0,0] , \"dscale\":[0.1,0.1,0.1] },\n",
        "   \"epochs\":5,\n",
        "   \"num_its\":100,                \n",
        "   \"balance\":{\"ratio\":0.5,\"autoweight\":1},\n",
        "\n",
        "   \"debug\":False,\n",
        "   \"patch_on_cpu\":True,\n",
        "   #\"hard_mining\":0.2,\n",
        "   #\"hard_mining_order\":'balance',\n",
        "\n",
        "   }\n",
        "\n",
        "\n",
        "# define, if you want, some validation data\n",
        "valid_ids = []\n",
        "\n",
        "outer_num_its = 10\n",
        "num_samp = 10\n",
        "print(\"\\n\\n\\n\\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> starting training\")\n",
        "import gc\n",
        "for i in range(0,outer_num_its):\n",
        "    \n",
        "    print(\"\\n========================================================= loading data =========================================================\")\n",
        "    with tf.device(\"/cpu:0\"):    \n",
        "        tset,lset,rset,subjs = get_data(num_samp)\n",
        "\n",
        "    themodel.train(tset,lset,resolutions=rset,**training,\n",
        "                   verbose=2,\n",
        "                   valid_ids=valid_ids)\n",
        "    \n",
        "    with tf.device(\"/cpu:0\"):  \n",
        "        del tset\n",
        "        del lset\n",
        "        gc.collect()\n",
        "    sys.stdout.flush()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apply the model"
      ],
      "metadata": {
        "id": "5x9sjYmnmxIU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nupJLt8raUuH"
      },
      "outputs": [],
      "source": [
        "#%%\n",
        "finame = taskname + dataset['test'][0][1:]\n",
        "ew =    themodel.apply_on_nifti(finame,'exmample.nii',repetitions=250,num_chunks=1,\n",
        "                                generate_type='random',\n",
        "                                augment={\"dphi\":0.2,'independent_augmentation':False},\n",
        "                                branch_factor=2,lazyEval=0.5,                                \n",
        "                                scale_to_original=False)\n",
        "\n",
        "\n",
        "plt.imshow(tf.squeeze(ew[1][:,:,10,0]))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Patchwork_MDhippocampus.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}